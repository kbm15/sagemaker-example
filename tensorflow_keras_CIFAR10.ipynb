{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Host a Keras Sequential Model\n",
    "\n",
    "This notebook shows how to train and host a Keras Sequential model on SageMaker. The model used for this notebook is a simple deep CNN that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is one of the most popular machine learning datasets. It consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)\n",
    "\n",
    "In this tutorial, we will train a deep CNN to recognize these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset\n",
    "Downloading the test and training data will take around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import sys\r\n",
      "import tarfile\r\n",
      "import boto3\r\n",
      "from six.moves import urllib\r\n",
      "from ipywidgets import FloatProgress\r\n",
      "from IPython.display import display\r\n",
      "\r\n",
      "\r\n",
      "def cifar10_download(data_dir='/tmp/cifar10_data', print_progress=True):\r\n",
      "    if not os.path.exists(data_dir):\r\n",
      "        os.makedirs(data_dir)\r\n",
      "\r\n",
      "    if os.path.exists(os.path.join(data_dir, 'cifar-10-batches-bin')):\r\n",
      "        print('cifar dataset already downloaded')\r\n",
      "        return\r\n",
      "\r\n",
      "    filename = 'cifar-10-binary.tar.gz'\r\n",
      "    filepath = os.path.join(data_dir, filename)\r\n",
      "\r\n",
      "    if not os.path.exists(filepath):\r\n",
      "        region = boto3.Session().region_name\r\n",
      "        boto3.Session().resource('s3', region_name=region).Bucket('sagemaker-sample-data-{}'.format(region)).download_file('tensorflow/cifar10/cifar-10-binary.tar.gz', '/tmp/cifar10_data/cifar-10-binary.tar.gz')\r\n",
      "\r\n",
      "    tarfile.open(filepath, 'r:gz').extractall(data_dir)\r\n"
     ]
    }
   ],
   "source": [
    "!cat utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.cifar10_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the dataset to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='/tmp/cifar10_data', key_prefix='data/DEMO-cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sagemaker_session.upload_data` will upload the CIFAR-10 dataset from this machine to a bucket named **sagemaker-{region}-{*your aws account number*}**, if you don't have this bucket yet, `sagemaker_session` will create it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete source code\n",
    "Here is the full source code for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "#     Licensed under the Apache License, Version 2.0 (the \"License\").\r\n",
      "#     You may not use this file except in compliance with the License.\r\n",
      "#     A copy of the License is located at\r\n",
      "#    \r\n",
      "#         https://aws.amazon.com/apache-2-0/\r\n",
      "#    \r\n",
      "#     or in the \"license\" file accompanying this file. This file is distributed\r\n",
      "#     on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\r\n",
      "#     express or implied. See the License for the specific language governing\r\n",
      "#     permissions and limitations under the License.\r\n",
      "\r\n",
      "from __future__ import absolute_import\r\n",
      "from __future__ import division\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import os\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\r\n",
      "from tensorflow.python.keras.models import Sequential\r\n",
      "from tensorflow.python.saved_model.signature_constants import PREDICT_INPUTS\r\n",
      "from tensorflow.python.training.rmsprop import RMSPropOptimizer\r\n",
      "\r\n",
      "HEIGHT = 32\r\n",
      "WIDTH = 32\r\n",
      "DEPTH = 3\r\n",
      "NUM_CLASSES = 10\r\n",
      "NUM_DATA_BATCHES = 5\r\n",
      "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 10000 * NUM_DATA_BATCHES\r\n",
      "BATCH_SIZE = 128\r\n",
      "INPUT_TENSOR_NAME = 'inputs_input'  # needs to match the name of the first layer + \"_input\"\r\n",
      "\r\n",
      "\r\n",
      "def keras_model_fn(hyperparameters):\r\n",
      "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\r\n",
      "    The model will be transformed into a TensorFlow Estimator before training and it will be saved in a \r\n",
      "    TensorFlow Serving SavedModel at the end of training.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        hyperparameters: The hyperparameters passed to the SageMaker TrainingJob that runs your TensorFlow \r\n",
      "                         training script.\r\n",
      "    Returns: A compiled Keras model\r\n",
      "    \"\"\"\r\n",
      "    model = Sequential()\r\n",
      "\r\n",
      "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(32, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Conv2D(64, (3, 3), padding='same'))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(64, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Flatten())\r\n",
      "    model.add(Dense(512))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Dropout(0.5))\r\n",
      "    model.add(Dense(NUM_CLASSES))\r\n",
      "    model.add(Activation('softmax'))\r\n",
      "    \r\n",
      "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\r\n",
      "\r\n",
      "    model.compile(loss='categorical_crossentropy',\r\n",
      "                  optimizer=opt,\r\n",
      "                  metrics=['accuracy'])\r\n",
      "\r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(hyperparameters):\r\n",
      "    \"\"\"This function defines the placeholders that will be added to the model during serving.\r\n",
      "    The function returns a tf.estimator.export.ServingInputReceiver object, which packages the \r\n",
      "    placeholders and the resulting feature Tensors together.\r\n",
      "    For more information: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst#creating-a-serving_input_fn\r\n",
      "    \r\n",
      "    Args:\r\n",
      "        hyperparameters: The hyperparameters passed to SageMaker TrainingJob that runs your TensorFlow \r\n",
      "                        training script.\r\n",
      "    Returns: ServingInputReceiver or fn that returns a ServingInputReceiver\r\n",
      "    \"\"\"\r\n",
      "    \r\n",
      "    # Notice that the input placeholder has the same input shape as the Keras model input\r\n",
      "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\r\n",
      "    \r\n",
      "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tensor}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, hyperparameters):\r\n",
      "    \"\"\"Returns input function that would feed the model during training\"\"\"\r\n",
      "    return _input(tf.estimator.ModeKeys.TRAIN,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, hyperparameters):\r\n",
      "    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\r\n",
      "    return _input(tf.estimator.ModeKeys.EVAL,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def _input(mode, batch_size, data_dir):\r\n",
      "    \"\"\"Uses the tf.data input pipeline for CIFAR-10 dataset.\r\n",
      "    Args:\r\n",
      "        mode: Standard names for model modes (tf.estimators.ModeKeys).\r\n",
      "        batch_size: The number of samples per batch of input requested.\r\n",
      "    \"\"\"\r\n",
      "    dataset = _record_dataset(_filenames(mode, data_dir))\r\n",
      "\r\n",
      "    # For training repeat forever.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.repeat()\r\n",
      "\r\n",
      "    dataset = dataset.map(_dataset_parser)\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # For training, preprocess the image and shuffle.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.map(_train_preprocess_fn)\r\n",
      "        dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "        # Ensure that the capacity is sufficiently large to provide good random\r\n",
      "        # shuffling.\r\n",
      "        buffer_size = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * batch_size\r\n",
      "        dataset = dataset.shuffle(buffer_size=buffer_size)\r\n",
      "\r\n",
      "    # Subtract off the mean and divide by the variance of the pixels.\r\n",
      "    dataset = dataset.map(\r\n",
      "        lambda image, label: (tf.image.per_image_standardization(image), label))\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # Batch results by up to batch_size, and then fetch the tuple from the\r\n",
      "    # iterator.\r\n",
      "    iterator = dataset.batch(batch_size).make_one_shot_iterator()\r\n",
      "    images, labels = iterator.get_next()\r\n",
      "\r\n",
      "    # We must use the default input tensor name PREDICT_INPUTS\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "\r\n",
      "def _train_preprocess_fn(image, label):\r\n",
      "    \"\"\"Preprocess a single training image of layout [height, width, depth].\"\"\"\r\n",
      "    # Resize the image to add four extra pixels on each side.\r\n",
      "    image = tf.image.resize_image_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\r\n",
      "\r\n",
      "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\r\n",
      "    image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\r\n",
      "\r\n",
      "    # Randomly flip the image horizontally.\r\n",
      "    image = tf.image.random_flip_left_right(image)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def _dataset_parser(value):\r\n",
      "    \"\"\"Parse a CIFAR-10 record from value.\"\"\"\r\n",
      "    # Every record consists of a label followed by the image, with a fixed number\r\n",
      "    # of bytes for each.\r\n",
      "    label_bytes = 1\r\n",
      "    image_bytes = HEIGHT * WIDTH * DEPTH\r\n",
      "    record_bytes = label_bytes + image_bytes\r\n",
      "\r\n",
      "    # Convert from a string to a vector of uint8 that is record_bytes long.\r\n",
      "    raw_record = tf.decode_raw(value, tf.uint8)\r\n",
      "\r\n",
      "    # The first byte represents the label, which we convert from uint8 to int32.\r\n",
      "    label = tf.cast(raw_record[0], tf.int32)\r\n",
      "\r\n",
      "    # The remaining bytes after the label represent the image, which we reshape\r\n",
      "    # from [depth * height * width] to [depth, height, width].\r\n",
      "    depth_major = tf.reshape(raw_record[label_bytes:record_bytes],\r\n",
      "                             [DEPTH, HEIGHT, WIDTH])\r\n",
      "\r\n",
      "    # Convert from [depth, height, width] to [height, width, depth], and cast as\r\n",
      "    # float32.\r\n",
      "    image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\r\n",
      "\r\n",
      "    return image, tf.one_hot(label, NUM_CLASSES)\r\n",
      "\r\n",
      "\r\n",
      "def _record_dataset(filenames):\r\n",
      "    \"\"\"Returns an input pipeline Dataset from `filenames`.\"\"\"\r\n",
      "    record_bytes = HEIGHT * WIDTH * DEPTH + 1\r\n",
      "    return tf.data.FixedLengthRecordDataset(filenames, record_bytes)\r\n",
      "\r\n",
      "\r\n",
      "def _filenames(mode, data_dir):\r\n",
      "    \"\"\"Returns a list of filenames based on 'mode'.\"\"\"\r\n",
      "    data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\r\n",
      "\r\n",
      "    assert os.path.exists(data_dir), ('Run cifar10_download_and_extract.py first '\r\n",
      "                                      'to download and extract the CIFAR-10 data.')\r\n",
      "\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        return [\r\n",
      "            os.path.join(data_dir, 'data_batch_%d.bin' % i)\r\n",
      "            for i in range(1, NUM_DATA_BATCHES + 1)\r\n",
      "        ]\r\n",
      "    elif mode == tf.estimator.ModeKeys.EVAL:\r\n",
      "        return [os.path.join(data_dir, 'test_batch.bin')]\r\n",
      "    else:\r\n",
      "        raise ValueError('Invalid mode: %s' % mode)\r\n"
     ]
    }
   ],
   "source": [
    "!cat cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a closer look:\n",
    "\n",
    "### The model function\n",
    "This function constitutes the main difference between TensorFlow and Keras models on SageMaker; Keras models have a `keras_model_fn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_fn(hyperparameters):\n",
    "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\n",
    "    The model will be transformed into a TensorFlow Estimator before training and it will be saved in a \n",
    "    TensorFlow Serving SavedModel at the end of training.\n",
    "\n",
    "    Args:\n",
    "        hyperparameters: The hyperparameters passed to the SageMaker TrainingJob that runs your TensorFlow \n",
    "                         training script.\n",
    "    Returns: A compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function builds and returns a compiled Keras model.\n",
    "\n",
    "**Note:** The first layer is named `PREDICT_INPUTS`. This serves as a workaround for a known issue where TensorFlow does not recognize the default (or any custom) name for the first layer of Keras models. Furthermore, note that we are wrapping our model in a `tf.keras.Model` before returning it. This serves as a workaround for a known issue where a Sequential model cannot be directly converted into an Estimator. See [here](https://github.com/tensorflow/tensorflow/issues/20552) for more information about the issue.\n",
    "\n",
    "### Input functions\n",
    "These functions are similar to those required by any other model using the TensorFlow Estimator API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    # Notice that the input placeholder has the same input shape as the Keras model input\n",
    "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\n",
    "    \n",
    "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\n",
    "    inputs = {INPUT_TENSOR_NAME: tensor}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.TRAIN,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.EVAL,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_` and `eval_` functions call the `_input` function which returns a properly processed and shuffled (for training) set of images and labels.\n",
    "\n",
    "## Create a training job using the SageMaker TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-tensorflow-2019-03-21-17-28-50-058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 17:28:51 Starting - Starting the training job...\n",
      "2019-03-21 17:28:53 Starting - Launching requested ML instances......\n",
      "2019-03-21 17:29:55 Starting - Preparing the instances for training...\n",
      "2019-03-21 17:30:55 Downloading - Downloading input data\n",
      "2019-03-21 17:30:55 Training - Downloading the training image..\n",
      "\u001b[31m2019-03-21 17:30:59,725 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2019-03-21 17:30:59,725 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2019-03-21 17:30:59,746 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,656 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,656 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,656 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,656 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,656 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,657 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,657 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:02,908 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:04,475 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff2b9e82d50>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[31mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[31mallow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:04,494 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:04,495 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:04,609 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,172 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,172 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,172 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,172 INFO - tensorflow - Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,322 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,452 INFO - tensorflow - Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,585 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,714 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:05,861 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:06,019 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:06,229 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:06,383 INFO - tensorflow - Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:06,533 INFO - tensorflow - Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:06,701 INFO - tensorflow - Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:06,888 INFO - tensorflow - Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:07,032 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:07,447 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:08,332 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:08,342 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:08,824 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/model.ckpt.\u001b[0m\n",
      "\n",
      "2019-03-21 17:30:59 Training - Training image download completed. Training in progress.\u001b[31m2019-03-21 17:31:17,315 INFO - tensorflow - loss = 2.3444705, step = 1\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:40,546 INFO - tensorflow - global_step/sec: 4.30451\u001b[0m\n",
      "\u001b[31m2019-03-21 17:31:40,547 INFO - tensorflow - loss = 2.091056, step = 101 (23.232 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:32:03,499 INFO - tensorflow - global_step/sec: 4.35684\u001b[0m\n",
      "\u001b[31m2019-03-21 17:32:03,499 INFO - tensorflow - loss = 1.9742846, step = 201 (22.952 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:32:26,351 INFO - tensorflow - global_step/sec: 4.37586\u001b[0m\n",
      "\u001b[31m2019-03-21 17:32:26,352 INFO - tensorflow - loss = 1.9126573, step = 301 (22.853 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:32:49,371 INFO - tensorflow - global_step/sec: 4.3442\u001b[0m\n",
      "\u001b[31m2019-03-21 17:32:49,371 INFO - tensorflow - loss = 1.85776, step = 401 (23.019 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:33:12,378 INFO - tensorflow - global_step/sec: 4.34637\u001b[0m\n",
      "\u001b[31m2019-03-21 17:33:12,486 INFO - tensorflow - loss = 1.7299168, step = 501 (23.114 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:33:35,438 INFO - tensorflow - global_step/sec: 4.33652\u001b[0m\n",
      "\u001b[31m2019-03-21 17:33:35,439 INFO - tensorflow - loss = 1.7070237, step = 601 (22.953 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:33:58,306 INFO - tensorflow - global_step/sec: 4.37293\u001b[0m\n",
      "\u001b[31m2019-03-21 17:33:58,307 INFO - tensorflow - loss = 1.7397318, step = 701 (22.868 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:34:21,237 INFO - tensorflow - global_step/sec: 4.36087\u001b[0m\n",
      "\u001b[31m2019-03-21 17:34:21,238 INFO - tensorflow - loss = 1.6674488, step = 801 (22.931 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:34:44,079 INFO - tensorflow - global_step/sec: 4.37795\u001b[0m\n",
      "\u001b[31m2019-03-21 17:34:44,080 INFO - tensorflow - loss = 1.7469566, step = 901 (22.842 sec)\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:06,807 INFO - tensorflow - Saving checkpoints for 1000 into s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,089 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,215 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,233 INFO - tensorflow - Starting evaluation at 2019-03-21-17:35:08\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,315 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,375 INFO - tensorflow - Restoring parameters from s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,599 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:08,609 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:09,572 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:10,328 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:11,119 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-03-21 17:35:11,872 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:12,625 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:13,434 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:14,187 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:14,878 INFO - tensorflow - Finished evaluation at 2019-03-21-17:35:14\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:14,878 INFO - tensorflow - Saving dict for global step 1000: accuracy = 0.44214794, global_step = 1000, loss = 1.56057\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,298 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1000: s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,641 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,741 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,741 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,741 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,741 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,741 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,741 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:15,828 INFO - tensorflow - Restoring parameters from s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:16,209 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:16,209 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:16,209 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:16,860 INFO - tensorflow - SavedModel written to: s3://sagemaker-eu-west-1-526952723483/sagemaker-tensorflow-2019-03-21-17-28-50-058/checkpoints/export/Servo/1553189715/saved_model.pb\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:17,073 INFO - tensorflow - Loss for final step: 1.5657151.\u001b[0m\n",
      "\u001b[31m2019-03-21 17:35:17,297 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1553189715\u001b[0m\n",
      "\n",
      "2019-03-21 17:36:07 Uploading - Uploading generated training model\n",
      "2019-03-21 17:36:07 Completed - Training job completed\n",
      "Billable seconds: 323\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_cnn.py',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       hyperparameters={'learning_rate': 1e-4, 'decay':1e-6},\n",
    "                       training_steps=1000, evaluation_steps=100,\n",
    "                       train_instance_count=2, train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Keras models have a known issue and cannot be used for distributed (multi-instance) training. Keep `train_instance_count == 1` until the TensorFlow/Keras team support this feature. See [here](https://github.com/tensorflow/tensorflow/issues/14504) for more information about the issue.\n",
    "\n",
    "\n",
    "## Deploy the trained model\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-tensorflow-2019-03-21-17-28-50-058\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-tensorflow-2019-03-21-17-28-50-058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions\n",
    "Prediction is not the focus of this notebook, so to verify the endpoint's functionality, we'll simply generate random data in the correct shape and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': {'activation_5': {'dtype': 1,\n",
       "   'tensor_shape': {'dim': [{'size': 1}, {'size': 10}]},\n",
       "   'float_val': [0.004174378234893084,\n",
       "    0.4450441002845764,\n",
       "    0.0013531706063076854,\n",
       "    0.004747383296489716,\n",
       "    0.0019372832030057907,\n",
       "    0.001180722494609654,\n",
       "    0.035327520221471786,\n",
       "    0.010748269036412239,\n",
       "    0.0006896215490996838,\n",
       "    0.4947974979877472]}},\n",
       " 'model_spec': {'name': 'generic_model',\n",
       "  'version': {'value': 1553189715},\n",
       "  'signature_name': 'serving_default'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "\n",
    "# The inputs key 'inputs_input' matches the Keras InputLayer name\n",
    "predictor.predict({'inputs_input': data}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial you need to delete the SageMaker Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-tensorflow-2019-03-21-17-28-50-058\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "sage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
